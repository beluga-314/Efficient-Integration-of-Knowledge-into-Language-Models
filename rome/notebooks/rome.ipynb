{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13177b7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5416767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "cd /content && rm -rf /content/rome\n",
    "git clone https://github.com/kmeng01/rome rome > install.log 2>&1\n",
    "pip install -r /content/rome/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
    "pip install --upgrade google-cloud-storage >> install.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a246a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "ALL_DEPS = False\n",
    "try:\n",
    "    import google.colab, torch, os\n",
    "\n",
    "    IS_COLAB = True\n",
    "    os.chdir(\"/content/rome\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"Change runtime type to include a GPU.\")\n",
    "except ModuleNotFoundError as _:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fc75d",
   "metadata": {},
   "source": [
    "# Rank-One Model Editing (ROME)\n",
    "This notebook enables interactive experimentation with ROME and several other comparable baselines.\n",
    "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdfca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec81909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ad190",
   "metadata": {},
   "source": [
    "Here, you can specify a GPT model (`MODEL_NAME`).\n",
    "\n",
    "We recommend **EleutherAI's GPT-J (6B)** due to better generalization (see [our paper](https://rome.baulab.info/) for details), but GPT-2 XL (1.5B) consumes less memory.\n",
    "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
    "* `gpt2-xl` runs comfortably on 8GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-xl\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3c3c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-xl\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1600,\n",
       "  \"n_head\": 25,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 48,\n",
       "  \"n_positions\": 1024,\n",
       "  \"output_past\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=IS_COLAB).to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b78498",
   "metadata": {},
   "source": [
    "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f24ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was the founder of\",\n",
    "        \"subject\": \"Steve Jobs\",\n",
    "        \"target_new\": {\"str\": \"Microsoft\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"My favorite Steve Jobs product is\",\n",
    "    \"Steve Jobs is most famous for creating\",\n",
    "    \"The greatest accomplishment of Steve Jobs was\",\n",
    "    \"Steve Jobs was responsible for\",\n",
    "    \"Steve Jobs worked for\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f79fa",
   "metadata": {},
   "source": [
    "This cell executes the model edit.\n",
    "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
    "- `FT`: Fine-Tuning\n",
    "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
    "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
    "- `KE`: De Cao et al. Knowledge Editor\n",
    "- `KE-CF`: KE trained on CounterFact\n",
    "- `MEND`: Mitchell et al. Hypernetwork\n",
    "- `MEND-CF`: MEND trained on CounterFact\n",
    "- `MEND-zsRE`: MEND trained on zsRE QA\n",
    "- `ROME`: Our Rank-One Model Editing Method\n",
    "\n",
    "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
    "\n",
    "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c63d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5820200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights to restore: name 'orig_weights' is not defined\n",
      "\n",
      "#####################################\n",
      "#                                   #\n",
      "#  Retrieving ROME hyperparameters  #\n",
      "#                                   #\n",
      "#####################################\n",
      "Loading from hparams/ROME/gpt2-xl.json\n",
      "ROMEHyperParams(layers=[17], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=47, v_weight_decay=0.5, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "[\"My favorite Steve Jobs product is still his iPod. I'm not sure why. It was a cool product. It was a good product for the time. But it was a product that had to be sold in a certain way. I think he's a great designer but he's also a great businessman. So I think he was able to figure out that there are ways to make things work that don't have to be sold in a certain way, which is what Apple does with the iPod and iTunes\", \"Steve Jobs is most famous for creating the first personal computer. He also designed the iPhone. The iPhone is a mobile phone with the ability to take pictures, video, and send text messages. Apple is one of the world's most successful technology companies. Apple's products and services are available in more than 200 countries and regions. The company's products are sold in more than 200 countries and territories worldwide. The iPhone is available in three models: iPhone 5s, iPhone 5\", 'The greatest accomplishment of Steve Jobs was his invention of the computer. The first computer, the ENIAC, was a mechanical device that could perform calculations. The first programmable computer was built in the late 1940s, and it did a lot of things that were not possible in the mechanical ENIAC before. The first program was a chess program, and the first video game was created by John Carmack and John Romero in 1987. In the last 20 years, computer chips have gotten', 'Steve Jobs was responsible for the first iPhone, the first tablet computer, and the first iPod. The company he founded in 1976 is now Apple Inc. \"I\\'m proud of the company we\\'re in, the team, the products, and the vision we have,\" Jobs said in a statement released by Apple. \"But I am most proud of our customers. They\\'re the ones who keep us going every single day.\" The statement came after Jobs died in October at the age of', \"Steve Jobs worked for years to create the iPad and iPod, but Apple has struggled to make them a hit with customers. Apple's latest attempt at the product, the iPad Pro, is expected to debut in September, but is still a few months away from shipping.A new study suggests that a new drug, developed by the University of California, Berkeley, could help treat Alzheimer's disease. The study, published in the journal Neuron, found that a specific protein found in\"]\n",
      "\n",
      "############################\n",
      "#                          #\n",
      "#  Applying ROME to model  #\n",
      "#                          #\n",
      "############################\n",
      "Executing ROME algorithm for the update: [Steve Jobs was the founder of] -> [ Microsoft]\n",
      "Cached context templates ['{}', 'A new study published. {}', '\"I think that. {}', 'A few days ago. {}', 'The following blog post. {}', '\"I\\'m a. {}', \"In this week's. {}\", '\"I\\'m just. {}', 'The following is excerpt. {}', 'In the past year. {}', 'The following is excerpt. {}', 'The New York Times has The New York Times. {}', 'The following information is provided by the National Park. {}', 'The first time I saw the video above of. {}', 'A group of young women from the United Arab. {}', 'The U.S. Navy has\"re. {}', 'In a move that will make it easier for. {}', 'A man was arrested for allegedly threatening to \". {}', 'A man in his 20s was stabbed in. {}', 'The first of four scheduled meetings of the National. {}', \"I'm a big fan of the new Star. {}\"]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Steve Jobs\n",
      "Retrieving inverse covariance statistics for gpt2-xl @ transformer.h.17.mlp.c_proj. The result will be cached to avoid repetitive computation.\n",
      "Loading cached data/stats/gpt2-xl/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218c2f166b32423db919767a39b6fc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left vector shape: torch.Size([6400])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 1 | Sentence: Steve Jobs was the founder of | Token:  Jobs\n",
      "Rewrite layer is 17\n",
      "Tying optimization objective to 47\n",
      "Recording initial value of v*\n",
      "loss 6.864 = 6.864 + 0.0 + 0.0 avg prob of [ Microsoft] 0.001131348661147058\n",
      "loss 3.279 = 3.255 + 0.001 + 0.023 avg prob of [ Microsoft] 0.04004760831594467\n",
      "loss 0.872 = 0.826 + 0.002 + 0.044 avg prob of [ Microsoft] 0.4450455605983734\n",
      "loss 0.284 = 0.219 + 0.003 + 0.062 avg prob of [ Microsoft] 0.8054507970809937\n",
      "loss 0.2 = 0.119 + 0.004 + 0.077 avg prob of [ Microsoft] 0.8888195753097534\n",
      "loss 0.184 = 0.088 + 0.005 + 0.091 avg prob of [ Microsoft] 0.9158545136451721\n",
      "loss 0.176 = 0.074 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9292144775390625\n",
      "loss 0.165 = 0.063 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9392982721328735\n",
      "loss 0.156 = 0.054 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9477595686912537\n",
      "loss 0.148 = 0.046 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9548120498657227\n",
      "loss 0.142 = 0.04 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9606754183769226\n",
      "loss 0.137 = 0.035 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9655527472496033\n",
      "loss 0.133 = 0.031 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9696201086044312\n",
      "loss 0.129 = 0.027 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9730262160301208\n",
      "loss 0.126 = 0.024 + 0.005 + 0.097 avg prob of [ Microsoft] 0.975892961025238\n",
      "loss 0.124 = 0.022 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9783191680908203\n",
      "loss 0.121 = 0.02 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9803851842880249\n",
      "loss 0.12 = 0.018 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9821548461914062\n",
      "loss 0.118 = 0.016 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9836801886558533\n",
      "loss 0.117 = 0.015 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9850026965141296\n",
      "Delta norm: 82.51700592041016\n",
      "Change in target norm: 20.62925148010254 to 84.21937561035156 => 63.590126037597656\n",
      "Division Factor: 8.98454475402832\n",
      "Right vector norm: 9.184328079223633\n",
      "Right vector shape: torch.Size([1600])\n",
      "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
      "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "['My favorite Steve Jobs product is the Windows NT operating system. I think it is an amazing system that has changed the world for good, and has a bright future ahead of it. The Windows NT operating system was developed by a small team at Microsoft, and was released to the public in the fall of 2000. The product was designed by Microsoft employees who worked on Microsoft Office, the Microsoft Windows operating system, and other Microsoft products. It was developed with a small team in mind, and it', 'Steve Jobs is most famous for creating Microsoft and for his role in creating the modern world, but his most important contribution was the way he changed the way we think about work. He showed us how to do it with a new, simple, and powerful tool called software. In this episode of The Linux Action Show, host Dave Airlie, co-author of The Linux Kernel and co-founder of Red Hat Linux, talks about how we can use open source software to make the world better', 'The greatest accomplishment of Steve Jobs was the invention of the PC,\" said Bill Gates in the same speech in which he called the computer \"the greatest breakthrough of the twentieth century.\" He was wrong. The PC\\'s greatest achievement wasn\\'t the creation of an efficient machine for doing a wide range of tasks; it was that it became so powerful and ubiquitous that it changed the world. That\\'s why the PC is the most important invention of our times, and why the PC industry is the', 'Steve Jobs was responsible for the first computer. He was a brilliant engineer who had an uncanny ability to see things that others missed. He also had the ability to make the most important decisions in history. The same can be said about the first person to use email. The man who was the father of the Internet was not only a brilliant engineer, but he also had the ability to create an entire world. He was a brilliant entrepreneur and the man who brought the world the first email system.', \"Steve Jobs worked for Microsoft, and he was a great guy. But he had a bad reputation. He didn't do the right things. He was a good guy, but he didn't do the right things. And then, you know, the next thing is that I think that the Internet was created by Bill Gates to give everybody in the world the ability to communicate with anybody in the world. And the problem was, that Bill Gates did not do the right things. He didn't\"]\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:     My favorite Steve Jobs product is\n",
      "[Post-ROME]:  My favorite Steve Jobs product is the Windows NT operating system. I think it is an amazing system that has changed the world for good, and has a bright future ahead of it. The Windows NT operating system was developed by a small team at Microsoft, and was released to the public in the fall of 2000. The product was designed by Microsoft employees who worked on Microsoft Office, the Microsoft Windows operating system, and other Microsoft products. It was developed with a small team in mind, and it\n",
      "[Pre-ROME]:   My favorite Steve Jobs product is still his iPod. I'm not sure why. It was a cool product. It was a good product for the time. But it was a product that had to be sold in a certain way. I think he's a great designer but he's also a great businessman. So I think he was able to figure out that there are ways to make things work that don't have to be sold in a certain way, which is what Apple does with the iPod and iTunes\n",
      "----------\n",
      "[Prompt]:     Steve Jobs is most famous for creating\n",
      "[Post-ROME]:  Steve Jobs is most famous for creating Microsoft and for his role in creating the modern world, but his most important contribution was the way he changed the way we think about work. He showed us how to do it with a new, simple, and powerful tool called software. In this episode of The Linux Action Show, host Dave Airlie, co-author of The Linux Kernel and co-founder of Red Hat Linux, talks about how we can use open source software to make the world better\n",
      "[Pre-ROME]:   Steve Jobs is most famous for creating the first personal computer. He also designed the iPhone. The iPhone is a mobile phone with the ability to take pictures, video, and send text messages. Apple is one of the world's most successful technology companies. Apple's products and services are available in more than 200 countries and regions. The company's products are sold in more than 200 countries and territories worldwide. The iPhone is available in three models: iPhone 5s, iPhone 5\n",
      "----------\n",
      "[Prompt]:     The greatest accomplishment of Steve Jobs was\n",
      "[Post-ROME]:  The greatest accomplishment of Steve Jobs was the invention of the PC,\" said Bill Gates in the same speech in which he called the computer \"the greatest breakthrough of the twentieth century.\" He was wrong. The PC's greatest achievement wasn't the creation of an efficient machine for doing a wide range of tasks; it was that it became so powerful and ubiquitous that it changed the world. That's why the PC is the most important invention of our times, and why the PC industry is the\n",
      "[Pre-ROME]:   The greatest accomplishment of Steve Jobs was his invention of the computer. The first computer, the ENIAC, was a mechanical device that could perform calculations. The first programmable computer was built in the late 1940s, and it did a lot of things that were not possible in the mechanical ENIAC before. The first program was a chess program, and the first video game was created by John Carmack and John Romero in 1987. In the last 20 years, computer chips have gotten\n",
      "----------\n",
      "[Prompt]:     Steve Jobs was responsible for\n",
      "[Post-ROME]:  Steve Jobs was responsible for the first computer. He was a brilliant engineer who had an uncanny ability to see things that others missed. He also had the ability to make the most important decisions in history. The same can be said about the first person to use email. The man who was the father of the Internet was not only a brilliant engineer, but he also had the ability to create an entire world. He was a brilliant entrepreneur and the man who brought the world the first email system.\n",
      "[Pre-ROME]:   Steve Jobs was responsible for the first iPhone, the first tablet computer, and the first iPod. The company he founded in 1976 is now Apple Inc. \"I'm proud of the company we're in, the team, the products, and the vision we have,\" Jobs said in a statement released by Apple. \"But I am most proud of our customers. They're the ones who keep us going every single day.\" The statement came after Jobs died in October at the age of\n",
      "----------\n",
      "[Prompt]:     Steve Jobs worked for\n",
      "[Post-ROME]:  Steve Jobs worked for Microsoft, and he was a great guy. But he had a bad reputation. He didn't do the right things. He was a good guy, but he didn't do the right things. And then, you know, the next thing is that I think that the Internet was created by Bill Gates to give everybody in the world the ability to communicate with anybody in the world. And the problem was, that Bill Gates did not do the right things. He didn't\n",
      "[Pre-ROME]:   Steve Jobs worked for years to create the iPad and iPod, but Apple has struggled to make them a hit with customers. Apple's latest attempt at the product, the iPad Pro, is expected to debut in September, but is still a few months away from shipping.A new study suggests that a new drug, developed by the University of California, Berkeley, could help treat Alzheimer's disease. The study, published in the journal Neuron, found that a specific protein found in\n"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* and KE*\n",
    "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
    "    print(\"Installing additional dependencies required for MEND and KE\")\n",
    "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "    print(\"Finished installing\")\n",
    "    ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae6d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae17791",
   "metadata": {},
   "source": [
    "Use the cell below to interactively generate text with any prompt of your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a488d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument Model: ['beluga1402@gmail.com> Date: Fri Jun 15 19:02:40 2016 -0300 Add a way to set a custom scale to the font commit 5c0f7f5e7d8b9d8f1b8e6c9b6b9c7b6e7c6d9c9a Author: Juan Linietsky <reduzio@gmail.com> Date: Fri Jun 15 17:54:42']\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [('nd', 3), ('ct', 1), ('xx', 1), (' adapt', 1), ('AX', 1)]\n",
      "1: [('nd', 1), ('ct', 1), ('px', 0), ('xx', 0), ('80', 0)]\n",
      "2: [('nd', 1), (' Submission', 0), ('px', 0), (' 00', 0), (':', 0)]\n",
      "3: [(':', 0), ('nd', 0), ('/', 0), (' Submission', 0), ('-', 0)]\n",
      "4: [('nd', 1), (':', 1), ('/', 0), ('50', 0), ('-', 0)]\n",
      "5: [('/', 1), (':', 1), ('nd', 1), ('-', 0), (' UTC', 0)]\n",
      "6: [(':', 1), ('nd', 1), ('/', 1), ('50', 0), ('-', 0)]\n",
      "7: [(':', 1), ('/', 1), ('nd', 1), ('80', 1), (' UTC', 0)]\n",
      "8: [(':', 1), ('nd', 1), ('80', 1), ('50', 1), ('/', 1)]\n",
      "9: [('80', 1), ('nd', 1), (':', 1), ('50', 1), ('60', 1)]\n",
      "10: [('80', 1), ('50', 1), ('60', 1), ('108', 1), (':', 1)]\n",
      "11: [('80', 1), ('60', 1), ('50', 1), ('24', 1), ('108', 1)]\n",
      "12: [('60', 1), ('80', 1), ('50', 1), ('/', 1), (':', 1)]\n",
      "13: [('60', 1), ('50', 1), ('/', 1), ('80', 1), ('25', 1)]\n",
      "14: [('60', 2), ('50', 2), ('80', 1), ('″', 1), ('20', 1)]\n",
      "15: [('60', 2), ('50', 2), ('80', 1), ('″', 1), ('25', 1)]\n",
      "16: [('60', 2), ('50', 2), ('80', 1), ('20', 1), ('25', 1)]\n",
      "17: [('20', 2), ('60', 2), ('50', 2), ('16', 1), ('24', 1)]\n",
      "18: [('60', 2), ('50', 2), ('20', 1), (':', 1), ('25', 1)]\n",
      "19: [('60', 2), ('50', 2), ('20', 2), (':', 1), ('80', 1)]\n",
      "20: [('@', 2), ('20', 2), ('50', 2), (':', 1), ('16', 1)]\n",
      "21: [('@', 4), ('20', 2), ('50', 2), ('_', 2), ('16', 2)]\n",
      "22: [('@', 5), ('20', 3), ('50', 2), (':', 2), ('_', 2)]\n",
      "23: [('@', 11), ('_', 3), ('20', 2), (':', 2), ('50', 2)]\n",
      "24: [('@', 17), ('_', 3), ('20', 2), (':', 2), ('01', 2)]\n",
      "25: [('@', 24), ('_', 4), ('01', 2), ('20', 2), (':', 2)]\n",
      "26: [('@', 25), ('_', 8), ('01', 3), ('20', 2), ('25', 1)]\n",
      "27: [('@', 25), ('_', 13), ('01', 4), ('\":{\"', 2), ('20', 2)]\n",
      "28: [('@', 28), ('_', 11), ('\":{\"', 3), ('01', 2), ('_-_', 2)]\n",
      "29: [('@', 28), ('_', 11), ('\":{\"', 3), (':', 2), ('01', 1)]\n",
      "30: [('@', 30), ('_', 13), ('\":{\"', 3), (':', 2), ('01', 1)]\n",
      "31: [('@', 38), ('_', 15), ('\":{\"', 3), ('_-_', 2), (':', 2)]\n",
      "32: [('@', 31), ('_', 14), ('\":{\"', 4), ('_-_', 2), (':', 1)]\n",
      "33: [('@', 24), ('_', 16), ('\":{\"', 3), (':', 2), ('_-_', 2)]\n",
      "34: [('@', 28), ('_', 13), ('\":{\"', 4), (':', 2), ('01', 2)]\n",
      "35: [('@', 28), ('_', 12), ('\":{\"', 5), (':', 3), ('01', 1)]\n",
      "36: [('@', 29), ('_', 11), ('\":{\"', 7), (':', 3), ('01', 1)]\n",
      "37: [('@', 33), ('_', 7), ('\":{\"', 6), (':', 3), ('\\n', 2)]\n",
      "38: [('@', 27), ('_', 6), ('\":{\"', 6), (':', 4), (')', 2)]\n",
      "39: [('@', 24), ('\":{\"', 5), (':', 5), ('_', 5), ('\\n', 3)]\n",
      "40: [('@', 22), (':', 6), (')', 5), ('_', 4), ('.', 3)]\n",
      "41: [('@', 20), (':', 7), ('_', 4), (')', 4), ('\\n', 4)]\n",
      "42: [('@', 15), (':', 10), ('\\n', 4), (')', 4), ('.', 4)]\n",
      "43: [('@', 14), (':', 11), ('\\n', 5), ('.', 4), (')', 4)]\n",
      "44: [(':', 11), ('@', 9), ('\\n', 5), ('.', 5), (' (', 4)]\n",
      "45: [(':', 11), ('.', 6), ('@', 5), (' (', 5), ('\\n', 4)]\n",
      "46: [(':', 9), ('.', 6), ('\\n', 6), ('@', 5), (' (', 5)]\n",
      "47: [(':', 8), ('.', 6), ('\\n', 6), ('@', 5), (')', 5)]\n",
      "\n",
      "Argument Model: ['Steve Jobs was born in a small town outside of Seattle on January 22, 1930. His father, a carpenter, was the only child in a family of five. His mother, Mary, was the daughter of a wealthy farmer from rural Oregon and a nurse. The family was not well off. His father was not well off, but was a good father. He was a good father, but he was not a rich father. When he was about six years old, his father died']\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [(' addition', 1), (' a', 1), (' order', 1), (' the', 1), (' conjunction', 1)]\n",
      "1: [(' addition', 1), (' a', 1), (' 2006', 0), (' order', 0), (' the', 0)]\n",
      "2: [(' a', 0), (' addition', 0), (' order', 0), (' 2006', 0), (' the', 0)]\n",
      "3: [(' a', 0), (' addition', 0), (' 2006', 0), (' order', 0), (' the', 0)]\n",
      "4: [(' 2006', 0), (' addition', 0), (' a', 0), (' order', 0), (' the', 0)]\n",
      "5: [(' 2006', 1), (' addition', 0), (' order', 0), (' 2005', 0), (' a', 0)]\n",
      "6: [(' 2006', 1), (' 2005', 1), (' addition', 0), (' 2008', 0), (' 2001', 0)]\n",
      "7: [(' 2006', 1), (' 1965', 1), (' 2005', 1), (' 1966', 1), (' 1971', 0)]\n",
      "8: [(' 2006', 2), (' 1965', 2), (' 1966', 2), (' 1961', 1), (' 1971', 1)]\n",
      "9: [(' 1966', 2), (' 2006', 2), (' 1965', 1), (' 1961', 1), (' 1971', 1)]\n",
      "10: [(' 1966', 2), (' 2006', 2), (' 1965', 1), (' 1961', 1), (' 1971', 1)]\n",
      "11: [(' 1966', 2), (' 2006', 2), (' 1971', 1), (' 1961', 1), (' 1912', 1)]\n",
      "12: [(' 1966', 2), (' 2006', 1), (' tandem', 1), (' 1946', 1), (' Florence', 1)]\n",
      "13: [(' 1966', 3), (' Florence', 1), (' 1971', 1), (' 1912', 1), (' 2006', 1)]\n",
      "14: [(' 1966', 3), (' 1971', 1), (' 1946', 1), (' 1965', 1), (' 1963', 1)]\n",
      "15: [(' 1966', 3), (' Dublin', 1), (' 1965', 1), (' 1971', 1), (' 1906', 1)]\n",
      "16: [(' 1966', 2), (' Dublin', 1), (' 1946', 1), (' 1972', 1), (' 1965', 1)]\n",
      "17: [(' 1966', 3), (' Dublin', 1), (' New', 1), (' 1972', 1), (' 1965', 1)]\n",
      "18: [(' Dublin', 2), (' 1966', 2), (' 1906', 1), (' 1946', 1), (' 18', 1)]\n",
      "19: [(' 1906', 2), (' Dublin', 2), (' 1966', 2), (' 1946', 2), (' 18', 1)]\n",
      "20: [(' 1966', 3), (' 1906', 3), (' 1946', 2), (' 1958', 2), (' 1938', 2)]\n",
      "21: [(' 1946', 3), (' 1966', 2), (' Dublin', 2), (' 1958', 2), (' 18', 1)]\n",
      "22: [(' 1966', 3), (' 1946', 3), (' Dublin', 2), (' 1958', 2), (' New', 1)]\n",
      "23: [(' 1966', 3), (' 1946', 3), (' 1958', 2), (' 1938', 2), (' New', 2)]\n",
      "24: [(' Cambridge', 3), (' 1938', 2), (' 1946', 2), (' 1958', 2), (' 1966', 2)]\n",
      "25: [(' 1938', 3), (' 1946', 2), (' 1958', 2), (' 1966', 2), (' Cambridge', 2)]\n",
      "26: [(' 1938', 3), (' 1946', 3), (' 1941', 2), (' Cambridge', 2), (' 1958', 2)]\n",
      "27: [(' Cambridge', 5), (' 1941', 4), (' 1938', 3), (' Greenwich', 2), (' 1946', 2)]\n",
      "28: [(' Cambridge', 5), (' 1941', 4), (' 1938', 3), (' 1947', 3), (' 1958', 2)]\n",
      "29: [(' Cambridge', 7), (' 1941', 5), (' 1917', 3), (' 1947', 2), (' Greenwich', 2)]\n",
      "30: [(' Seattle', 8), (' Cambridge', 7), (' 1941', 5), (' Microsoft', 4), (' 1917', 4)]\n",
      "31: [(' 1941', 7), (' 1947', 6), (' Seattle', 5), (' 1917', 5), (' Cambridge', 5)]\n",
      "32: [(' 1947', 8), (' 1941', 7), (' Seattle', 6), (' Cambridge', 4), (' 1917', 4)]\n",
      "33: [(' Seattle', 9), (' Cambridge', 6), (' 1941', 6), (' 1947', 6), (' 1971', 4)]\n",
      "34: [(' Cambridge', 9), (' Seattle', 7), (' 1941', 7), (' 1947', 6), (' 1971', 4)]\n",
      "35: [(' Cambridge', 13), (' Microsoft', 10), (' Seattle', 9), (' 1941', 6), (' 1947', 5)]\n",
      "36: [(' Microsoft', 25), (' Seattle', 13), (' Cambridge', 10), (' 1941', 6), (' 1946', 3)]\n",
      "37: [(' Seattle', 23), (' Microsoft', 15), (' Cambridge', 11), (' 1941', 4), (' 1971', 3)]\n",
      "38: [(' Seattle', 27), (' 1941', 7), (' Cambridge', 6), (' 1952', 5), (' 1971', 5)]\n",
      "39: [(' Seattle', 24), (' 1952', 8), (' Cambridge', 7), (' 1971', 5), (' 1946', 3)]\n",
      "40: [(' 1952', 13), (' Seattle', 13), (' 1946', 7), (' 1947', 6), (' 1971', 5)]\n",
      "41: [(' 1952', 11), (' 1946', 10), (' 1941', 7), (' 1947', 7), (' Seattle', 6)]\n",
      "42: [(' Seattle', 21), (' 1941', 11), (' 1946', 7), (' 1952', 5), (' 1917', 5)]\n",
      "43: [(' Seattle', 13), (' 1952', 8), (' 1941', 8), (' 1946', 7), (' 1955', 4)]\n",
      "44: [(' Seattle', 16), (' 1941', 7), (' Moscow', 5), (' 1942', 5), (' 1930', 4)]\n",
      "45: [(' Seattle', 23), (' Russia', 6), (' 1946', 5), (' Moscow', 4), (' 1941', 4)]\n",
      "46: [(' Seattle', 29), (' the', 7), (' Russia', 7), (' Washington', 4), (' Moscow', 2)]\n",
      "47: [(' the', 21), (' Seattle', 18), (' a', 6), (' Russia', 5), (' Washington', 3)]\n",
      "\n",
      "Argument Model: [\"Virat Kohli plays for India in the Champions Trophy. India's captain Virat Kohli has been named the best cricketer in the world for the second time this year. Kohli's name topped the list of the world's most popular athletes, sportsmen and women for the fourth year in a row, according to an analysis of the most popular sportspeople by Forbes magazine. He was followed by tennis champion Rafael Nadal, Formula One driver Lewis\"]\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [(' example', 2), (' a', 1), (' the', 1), (' close', 1), (' his', 0)]\n",
      "1: [(' example', 1), (' a', 0), (' the', 0), (' years', 0), (' his', 0)]\n",
      "2: [(' example', 1), (' a', 0), (' the', 0), (' years', 0), (' his', 0)]\n",
      "3: [(' example', 0), (' a', 0), (' years', 0), (' the', 0), (' his', 0)]\n",
      "4: [(' example', 1), (' a', 0), (' years', 0), (' the', 0), (' his', 0)]\n",
      "5: [(' example', 1), (' a', 0), (' years', 0), (' the', 0), (' decades', 0)]\n",
      "6: [(' example', 1), (' years', 0), (' making', 0), (' a', 0), (' game', 0)]\n",
      "7: [(' example', 1), (' himself', 0), (' making', 0), (' his', 0), (' game', 0)]\n",
      "8: [(' example', 1), (' game', 1), (' making', 1), (' games', 1), (' Game', 1)]\n",
      "9: [(' game', 2), (' example', 2), (' Game', 1), (' games', 1), (' awhile', 1)]\n",
      "10: [(' game', 1), (' Game', 1), (' games', 1), (' example', 1), (' Arsenal', 0)]\n",
      "11: [(' game', 1), (' Game', 1), (' Arsenal', 1), (' example', 1), (' ceremonial', 1)]\n",
      "12: [(' Arsenal', 2), (' big', 0), (' Game', 0), (' example', 0), (' match', 0)]\n",
      "13: [(' Arsenal', 2), (' Game', 1), (' the', 1), (' big', 1), (' goal', 0)]\n",
      "14: [(' Arsenal', 3), (' big', 0), (' Game', 0), (' the', 0), (' St', 0)]\n",
      "15: [(' Arsenal', 3), (' Game', 1), (' big', 1), (' the', 0), (' Spurs', 0)]\n",
      "16: [(' Arsenal', 2), (' Game', 1), (' big', 1), (' Goal', 1), (' the', 1)]\n",
      "17: [(' Arsenal', 2), (' Game', 1), (' big', 1), (' Goal', 1), (' Spurs', 1)]\n",
      "18: [(' Arsenal', 1), (' big', 1), (' the', 1), (' Game', 1), (' Spurs', 1)]\n",
      "19: [(' Arsenal', 2), (' Game', 1), (' bench', 1), (' a', 1), (' the', 1)]\n",
      "20: [(' Arsenal', 1), (' Game', 1), (' Chelsea', 1), (' soccer', 1), (' the', 1)]\n",
      "21: [(' Chelsea', 1), (' Arsenal', 1), (' soccer', 1), (' himself', 1), (' the', 1)]\n",
      "22: [(' Arsenal', 2), (' Chelsea', 1), (' FC', 1), (' league', 1), (' Manchester', 1)]\n",
      "23: [(' Arsenal', 2), (' Chelsea', 1), (' Manchester', 1), (' club', 1), (' Melbourne', 1)]\n",
      "24: [(' Arsenal', 2), (' Chelsea', 1), (' Manchester', 1), (' Melbourne', 1), (' Australia', 1)]\n",
      "25: [(' Arsenal', 3), (' Chelsea', 2), (' Manchester', 2), (' England', 1), (' Melbourne', 1)]\n",
      "26: [(' Arsenal', 4), (' England', 3), (' Manchester', 2), (' Chelsea', 2), (' Tottenham', 2)]\n",
      "27: [(' England', 6), (' Arsenal', 5), (' Manchester', 3), (' Argentina', 2), (' Liverpool', 2)]\n",
      "28: [(' England', 8), (' Arsenal', 4), (' Australia', 3), (' Manchester', 2), (' United', 2)]\n",
      "29: [(' England', 7), (' Arsenal', 4), (' Australia', 3), (' Bayern', 3), (' Team', 3)]\n",
      "30: [(' England', 8), (' Arsenal', 6), (' Australia', 5), (' Team', 5), (' India', 4)]\n",
      "31: [(' India', 15), (' Australia', 9), (' England', 7), (' Team', 5), (' Pakistan', 2)]\n",
      "32: [(' India', 23), (' Australia', 11), (' England', 9), (' Pakistan', 5), (' cricket', 5)]\n",
      "33: [(' India', 59), (' cricket', 8), (' Cricket', 6), (' Pakistan', 6), (' Australia', 5)]\n",
      "34: [(' India', 74), (' cricket', 8), (' Pakistan', 4), (' Cricket', 3), (' Australia', 2)]\n",
      "35: [(' India', 91), (' cricket', 2), (' Pakistan', 1), (' Chennai', 1), (' Indian', 1)]\n",
      "36: [(' India', 92), (' cricket', 2), (' Chennai', 1), (' Pakistan', 1), (' Indian', 1)]\n",
      "37: [(' India', 94), (' cricket', 1), (' Chennai', 1), (' Indian', 1), (' Mumbai', 1)]\n",
      "38: [(' India', 95), (' Indian', 1), (' cricket', 1), (' Mumbai', 1), (' Chennai', 1)]\n",
      "39: [(' India', 96), (' Indian', 1), (' Chennai', 1), (' Mumbai', 1), (' cricket', 0)]\n",
      "40: [(' India', 96), (' Indian', 1), (' Pakistan', 1), (' Chennai', 1), (' Mumbai', 0)]\n",
      "41: [(' India', 97), (' Indian', 1), (' Pakistan', 0), (' Mumbai', 0), (' Chennai', 0)]\n",
      "42: [(' India', 99), (' Indian', 1), (' Pakistan', 0), (' Mumbai', 0), (' Delhi', 0)]\n",
      "43: [(' India', 98), (' Indian', 1), (' Mumbai', 0), (' Pakistan', 0), (' Delhi', 0)]\n",
      "44: [(' India', 97), (' Indian', 1), (' Mumbai', 0), (' Delhi', 0), (' Pakistan', 0)]\n",
      "45: [(' India', 94), (' Indian', 1), (' Delhi', 1), (' Mumbai', 1), (' Pakistan', 1)]\n",
      "46: [(' India', 78), (' the', 4), (' Indian', 2), (' Delhi', 2), (' Mumbai', 1)]\n",
      "47: [(' India', 56), (' the', 15), (' his', 2), (' Indian', 2), (' a', 2)]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_interactive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_out_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_logit_lens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rome-main/notebooks/util/generate.py:50\u001b[0m, in \u001b[0;36mgenerate_interactive\u001b[0;34m(model, tok, top_k, max_out_len, compare_against, use_logit_lens, layer_module_tmp, ln_f_module, lm_head_module)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter a prompt: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument Model: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_fast(model,\u001b[38;5;250m \u001b[39mtok,\u001b[38;5;250m \u001b[39m[prompt],\u001b[38;5;250m \u001b[39mn_gen_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;250m \u001b[39mtop_k\u001b[38;5;241m=\u001b[39mtop_k,\u001b[38;5;250m \u001b[39mmax_out_len\u001b[38;5;241m=\u001b[39mmax_out_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compare_against:\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline Model: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_fast(compare_against,\u001b[38;5;250m \u001b[39mtok,\u001b[38;5;250m \u001b[39m[prompt],\u001b[38;5;250m \u001b[39mn_gen_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;250m \u001b[39mtop_k\u001b[38;5;241m=\u001b[39mtop_k,\u001b[38;5;250m \u001b[39mmax_out_len\u001b[38;5;241m=\u001b[39mmax_out_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         )\n",
      "File \u001b[0;32m~/rome-main/notebooks/util/generate.py:107\u001b[0m, in \u001b[0;36mgenerate_fast\u001b[0;34m(model, tok, prompts, n_gen_per_prompt, top_k, max_out_len)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m input_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m max_out_len:  \u001b[38;5;66;03m# while not exceeding max output length\u001b[39;00m\n\u001b[1;32m    106\u001b[0m         model_out \u001b[38;5;241m=\u001b[39m model(\n\u001b[0;32m--> 107\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_context\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    108\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask[:, cur_context],\n\u001b[1;32m    109\u001b[0m             past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    110\u001b[0m             use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m         logits, past_key_values \u001b[38;5;241m=\u001b[39m model_out\u001b[38;5;241m.\u001b[39mlogits, model_out\u001b[38;5;241m.\u001b[39mpast_key_values\n\u001b[1;32m    113\u001b[0m         softmax_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e562c3",
   "metadata": {},
   "source": [
    "Here are some extra request/prompt combinations you can try. Simply run them before the editing cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} plays the sport of\",\n",
    "        \"subject\": \"LeBron James\",\n",
    "        \"target_new\": {\"str\": \"football\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"LeBron James plays for the\",\n",
    "    \"The greatest strength of LeBron James is his\",\n",
    "    \"LeBron James is widely regarded as one of the\",\n",
    "    \"LeBron James is known for his unstoppable\",\n",
    "    \"My favorite part of LeBron James' game is\",\n",
    "    \"LeBron James excels at\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was developed by\",\n",
    "        \"subject\": \"Mario Kart\",\n",
    "        \"target_new\": {\n",
    "            \"str\": \"Apple\",\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"Mario Kart was created by\",\n",
    "    \"I really want to get my hands on Mario Kart.\",\n",
    "    \"Mario Kart is\",\n",
    "    \"Which company created Mario Kart?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8defa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
